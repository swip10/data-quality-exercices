{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1> Introduction au Machine Learning avec scikit-learn </h1></center>\n",
    "<center><h2> Régression linéaire </h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> L'objectif de cet exercice est de se familiariser avec la régression linéaire. <br>\n",
    "> La régression linéaire est l'un des premiers modèles prédictifs à avoir été étudié et est aujourd'hui le modèle le plus populaire pour les applications pratiques grâce à sa simplicité.\n",
    "\n",
    "### Régression Linéaire Univariée\n",
    "\n",
    "> Dans le modèle linéaire univarié, nous disposons de deux variables, $y$ appelée variable cible ou *target* et $x$ appelée variable *explicative*. <br>\n",
    "> La régression linéaire consiste à modéliser le lien entre ces deux variables par une fonction affine. Ainsi, la formule du modèle linéaire univarié est donnée par :\n",
    "> $$y \\approx \\beta_1 x + \\beta_0 $$\n",
    "> où :\n",
    ">> * $y$ est la variable que nous voulons prédire.\n",
    ">>\n",
    ">>\n",
    ">> * $x$ est la variable explicative.\n",
    ">>\n",
    ">>\n",
    ">> * $\\beta_1$ et $\\beta_0$ sont les paramètres de la fonction affine. $\\beta_1$ définira sa **pente** et $\\beta_0$ définira son ordonnée à l'origine (également appelée **biais**).\n",
    ">\n",
    "> **Le but de la régression linéaire est d'estimer les meilleurs paramètres $\\beta_0$ et $\\beta_1$ pour prédire la variable $y$ à partir d'une valeur donnée de $x$**.\n",
    ">\n",
    "> Pour avoir une intuition de la Régression Linéaire Univariée, regardons l'exemple interactif ci-dessous.\n",
    "\n",
    "* **(a)** Exécuter la cellule suivante pour afficher la figure interactive. Dans cette figure, nous avons simulé un jeu de données.\n",
    "\n",
    "\n",
    "* **(b)** Essayez de trouver à l'aide des curseurs de l'onglet `Régression` les paramètres $\\beta_0$ et $\\beta_1$ qui se rapprochent le mieux de tous les points de l'ensemble de données.\n",
    "\n",
    "\n",
    "* **(c)** Quel est l'effet de chacun des paramètres sur la fonction de régression ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from widgets import regression_widget\n",
    "\n",
    "regression_widget()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "###  Régression Linéaire Multiple\n",
    "\n",
    "> La régression linéaire multiple consiste à modéliser le lien entre une variable cible $y$ et **plusieurs variables explicatives** $x_1$, $x_2$, ... ,$x_p$, souvent appelées *features* en anglais :\n",
    "> $$\n",
    "\\begin{align}\n",
    "    y & \\approx β_0 + β_1 x_1 + β_2 x_2 + ⋯ + β_p x_p \\\\\n",
    "      & \\approx β_0+ \\sum_{j=1}^{p} β_j x_j \n",
    "\\end{align}\n",
    "$$\n",
    ">\n",
    "> Il y a maintenant $p + 1$ paramètres $\\beta_j$ à trouver.\n",
    "\n",
    "\n",
    "## 1. Utilisation de scikit-learn pour la régression linéaire\n",
    "\n",
    "> Nous allons maintenant apprendre à utiliser la bibliothèque **`scikit-learn`** afin de résoudre un problème de Machine Learning avec une **régression linéaire**.\n",
    ">\n",
    "> Au cours des exercices suivants, l'objectif sera de prédire le **prix de vente d'une voiture** en fonction de ses **caractéristiques**.\n",
    "\n",
    "### Importation du jeu de données \n",
    "\n",
    "> Le jeu de données que nous utiliserons dans la suite contient de nombreuses caractéristiques à propos de différentes voitures de 1985.\n",
    ">\n",
    "> Par simplicité, seules les variables numériques ont été gardées et les lignes comprenant des valeurs manquantes ont été supprimées.\n",
    "\n",
    "* **(a)** Importer le module `pandas` sous l'alias `pd`.\n",
    "\n",
    "\n",
    "* **(b)** Dans un `DataFrame` nommé `df`, importer le jeu de données `automobiles.csv` à l'aide de la fonction `read_csv` de `pandas`. Ce fichier se trouve dans le même dossier que l'environnement d'exécution de ce notebook.\n",
    "\n",
    "\n",
    "* **(c)** Afficher les 5 premières lignes de `df` pour vérifier que l'importation s'est bien déroulée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> * La variable `symboling` correspond au degré de risque vis-à-vis de l'assureur (risque d'accident, panne, etc).\n",
    ">\n",
    ">\n",
    "> * La variable `normalized_losses` est le coût moyen relatif par an d'assurance du véhicule. Cette valeur est normalisée par rapport aux voitures de même type (SUV, utilitaire, sportive, etc).\n",
    ">\n",
    ">\n",
    "> * Les 13 variables suivantes concernent les caractéristiques techniques des voitures comme la largeur, la longueur, la cylindrée du moteur, la puissance en chevaux, etc.<br>\n",
    ">\n",
    ">\n",
    "> * La dernière variable `price` correspond au prix de vente du véhicule. C'est la variable que nous chercherons à prédire.\n",
    "\n",
    "\n",
    "### Séparation des variables explicatives de la variable cible\n",
    "\n",
    "> Nous allons maintenant créer deux `DataFrames`, un contenant les variables explicatives et un autre contenant la variable cible `price`.\n",
    "\n",
    "* **(d)** Dans un `DataFrame` nommé `X`, faire une copie des variables explicatives de notre jeu de données, c'est-à-dire toutes les variables **sauf** `price`.\n",
    "\n",
    "\n",
    "* **(e)** Dans un `DataFrame` nommé `y`, faire une copie de la variable cible `price`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Séparation des données en jeu d'entraînement et de test\n",
    "\n",
    "> Nous allons maintenant séparer notre jeu de données en deux parties. Une partie d'**entraînement** et une partie de **test**. Cette étape est **extrêmement** importante en Data Science.\n",
    ">\n",
    "> En effet, comme leurs noms l'indiquent : \n",
    ">> * la partie d'entraînement sert à « entraîner » le modèle, c'est-à-dire trouver les paramètres $\\beta_0$, ..., $\\beta_p$ optimaux pour ce jeu de données.\n",
    ">>\n",
    ">>\n",
    ">> * la partie de test sert à « tester » le modèle entraîné en évaluant sa capacité à **généraliser** ses prédictions sur des données qu'il n'a encore **jamais vues**.\n",
    ">\n",
    "> Une fonction très utile pour effectuer cette opération est la fonction `train_test_split` du sous-module `model_selection` de **`scikit-learn`**.\n",
    "\n",
    "* **(f)** Exécuter la cellule suivante pour importer la fonction `train_test_split`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> Cette fonction s'utilise ainsi :\n",
    ">\n",
    "> ```python\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "> ```\n",
    ">\n",
    ">> * `X_train` et `y_train` sont les variables explicatives et cible du jeu de données d'**entraînement**.\n",
    ">>\n",
    ">>\n",
    ">> * `X_test` et `y_test` sont les variables explicatives et cible du jeu de données de **test**.\n",
    ">>\n",
    ">>\n",
    ">> * L'argument `test_size` correspond à la **proportion** du jeu de données que nous voulons garder pour le jeu de test. Dans l'exemple précédent, cette proportion correspond à 20% du jeu de données initial.\n",
    "\n",
    "* **(g)** À l'aide de la fonction `train_test_split`, séparer le jeu de données en une partie d'entraînement (`X_train`,`y_train`)  et une partie de test (`X_test`, `y_test`) de sorte que la partie de test contienne **15% du jeu de données initial** avec un `random_state` de 20.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Création du modèle de régression\n",
    "\n",
    "> Pour entraîner un modèle de régression linéaire sur ce jeu de données, nous allons utiliser la classe **`LinearRegression`** contenue dans le sous-module `linear_model` de `scikit-learn`. \n",
    "\n",
    "* **(h)** Exécuter la cellule suivante pour importer la classe `LinearRegression`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> L'API de `scikit-learn` permet d'entraîner et évaluer des modèles très facilement. Toutes les classes de modèles de scikit-learn disposent des deux méthodes suivantes :\n",
    ">> * **`fit`** : Entraîne le modèle sur un jeu de données. \n",
    ">>\n",
    ">>\n",
    ">> * **`predict`** : Effectue une prédiction à partir de variables explicatives. \n",
    ">\n",
    "> Voici un exemple d'utilisation d'un modèle avec scikit-learn :\n",
    "> \n",
    "> ```python\n",
    "># Instanciation du modèle\n",
    "> linreg = LinearRegression()      \n",
    ">    \n",
    "># Entraînement du modèle sur le jeu d'entraînement\n",
    "> linreg.fit(X_train, y_train)        \n",
    ">  \n",
    "># Prédiction de la variable cible pour le jeu de données test. Ces prédictions sont stockées dans y_pred\n",
    "> y_pred = linreg.predict(X_test)                                           \n",
    ">    ```\n",
    "\n",
    "* **(i)** Instancier un modèle `LinearRegression` nommé **`lr`**.\n",
    "\n",
    "\n",
    "* **(j)** Entraîner `lr` sur le jeu de données d'entraînement.\n",
    "\n",
    "\n",
    "* **(k)** Effectuer une prédiction sur les données d'entraînement. Stocker ces prédictions dans `y_pred_train`.\n",
    "\n",
    "\n",
    "* **(l)** Effectuer une prédiction sur les données de test. Stocker ces prédictions dans `y_pred_test`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Evaluation de la performance du modèle\n",
    "\n",
    "> Afin d'évaluer la **qualité des prédictions du modèle** obtenues grâce aux paramètres $\\beta_0$, ..., $\\beta_j$, il existe plusieurs métriques (ou *metrics* en anglais) dans la bibliothèque `scikit-learn`.\n",
    ">\n",
    "> L'une des métriques les plus utilisées pour la régression est l'**Erreur Quadratique Moyenne** (ou *Mean Squared Error* en anglais) qui existe sous le nom de `mean_squared_error` dans le sous-module `metrics` de `scikit-learn`.\n",
    ">\n",
    "> Cette fonction consiste à calculer la moyenne des distances entre les **variables cibles** et les **prédictions obtenues** grâce à la fonction de régression. \n",
    ">\n",
    "> La figure interactive suivante permet de visualiser comment est calculée cette erreur en fonction de $\\beta_1$ :\n",
    ">> * Les points **bleus** représentent le **jeu de données** pour lequel on veut évaluer la qualité des prédictions. En général il s'agit du jeu de données **test**.\n",
    ">>\n",
    ">>\n",
    ">> * La droite **rouge** est la fonction de régression paramétrée par $\\beta_1$. Dans cet exemple, $\\beta_0$ est fixé à 0 pour simplifier l'illustration.\n",
    ">>\n",
    ">>\n",
    ">> * Les traits verts sont les distances entre la **variable cible** et les prédictions obtenues grâce à la fonction de régression paramétrisée par $\\beta_1$. \n",
    ">\n",
    "> **L'erreur quadratique moyenne n'est en fait que la moyenne de ces distances élevées au carré.**\n",
    "\n",
    "* **(m)** Exécuter la cellule suivante pour afficher la figure interactive.\n",
    "\n",
    "\n",
    "* **(n)** A l'aide du curseur se trouvant sous la figure, essayer de trouver une valeur de $\\beta_1$ qui minimise l'erreur quadratique moyenne. Est-ce que cette valeur est unique ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from widgets import interactive_MSE\n",
    "\n",
    "interactive_MSE()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> La fonction `mean_squared_error` de `scikit-learn` s'utilise ainsi :\n",
    ">\n",
    "> ```python\n",
    "    mean_squared_error(y_true, y_pred)\n",
    "> ```\n",
    "> où :\n",
    ">> * `y_true` correspond aux vraies valeurs de la variable cible.\n",
    ">>\n",
    ">>\n",
    ">> * `y_pred` correspond aux valeurs prédites par notre modèle.\n",
    "\n",
    "* **(o)** Importer la fonction **`mean_squared_error`** à partir du sous-module `sklearn.metrics`.\n",
    "\n",
    "\n",
    "* **(p)** Évaluer la qualité de prédiction du modèle sur **les données d'entraînement**. Stocker le résultat dans une variable nommée `mse_train`.\n",
    "\n",
    "\n",
    "* **(q)** Évaluer la qualité de prédiction du modèle sur **les données de test**. Stocker le résultat dans une variable nommée `mse_test`.\n",
    "\n",
    "\n",
    "* **(r)** Pourquoi la MSE est-elle supérieure sur les données de test ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> L'erreur quadratique moyenne que vous trouverez devrait être de plusieurs millions sur les données de test, ce qui peut être difficile à interpréter. \n",
    ">\n",
    "> C'est pourquoi nous allons utiliser une autre métrique, l'**erreur absolue moyenne** (*Mean Absolute Error* en anglais) qui est à la même échelle que la variable cible.\n",
    "\n",
    "* **(s)** Importer la fonction `mean_absolute_error` à partir du sous-module `sklearn.metrics`.\n",
    "\n",
    "\n",
    "* **(t)** Évaluer la qualité de prédiction sur les données de test et d'entraînement à l'aide de l'erreur absolue moyenne. \n",
    "\n",
    "\n",
    "* **(u)** À partir du `DataFrame` `df`, calculer le prix d'achat moyen sur tous les véhicules. Est-ce que les prédictions du modèle vous paraissent fiables ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## 2. Surapprentissage sur les données avec un autre modèle de régression\n",
    "\n",
    "\n",
    "> Nous venons de voir qu'avec la classe `LinearRegression` de `scikit-learn`, le modèle parvenait à apprendre sur les données d'entraînement et à généraliser sur les données de test avec une erreur de 20% en moyenne.\n",
    ">\n",
    "> Dans ce qui suit nous allons créer un autre modèle de régression qui apprend très bien sur les données d'entraînement mais qui généralise très mal sur les données test : c'est ce qu'on appelle du **surapprentissage** ou de l'***overfitting*** en anglais.\n",
    ">\n",
    "> Pour cela nous allons utiliser un modèle de Machine Learning appelé Gradient Boosting Regressor connu pour ses propriétés de surapprentissage.\n",
    "\n",
    "\n",
    "* **(a)** Exécuter la cellule suivante pour importer la classe `GradientBoostingRegressor` contenue dans le sous-module `ensemble` de `scikit-learn` et instancier un modèle `GradientBoostingRegressor` nommé **`gbr`**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Ces arguments ont été choisis pour surapprendre le plus possible\n",
    "# Ne pas les utiliser en pratique\n",
    "gbr = GradientBoostingRegressor(n_estimators = 1000,\n",
    "                                max_depth = 10000,\n",
    "                                max_features = 15,\n",
    "                                validation_fraction = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "* **(b)** Entraîner le modèle **`gbr`** grâce à sa méthode **`fit`**.\n",
    "\n",
    "\n",
    "* **(c)** Effectuer une prédiction sur les données de test et d'entraînement. Stocker ces prédictions dans `y_pred_test_gbr` et `y_pred_train_gbr`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> Après avoir défini notre modèle, l'avoir entraîné sur les données d'entraînement et avoir réalisé les prédictions, il faut ensuite évaluer ses performances.\n",
    "\n",
    "* **(d)** Calculer la MSE sur les données d'**entraînement** et les données de **test** grâce à la fonction `mean_squared_error` puis afficher les résultats.\n",
    "\n",
    "\n",
    "* **(e)** Calculer la MAE pour les données d'**entraînement**  et les données de **test** grâce à la fonction `mean_absolute_error` puis afficher les résultats.\n",
    "\n",
    "\n",
    "* **(f)** Après avoir calculé la moyenne de la colonne `price`, calculer l'**erreur moyenne du modèle** sur les données du jeu de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> Voici un exemple de résultats que nous pourrions obtenir avec ces deux modèles.\n",
    "> \n",
    "> Pour la **régression linéaire avec `LinearRegression`** nous avions :\n",
    ">> * MAE train lr: 1680.4078748721086\n",
    ">>\n",
    ">>\n",
    ">> * MAE test lr: 1773.9135394428085\n",
    "> \n",
    "> Pour la **régression avec `GradientBoostingRegressor`** nous avons :\n",
    ">> * MAE train gbr: 20.740740828767215\n",
    ">>\n",
    ">>\n",
    ">> * MAE test gbr: 1442.6573741134125  \n",
    "> \n",
    "> L'erreur absolue moyenne obtenue sur le jeu d'entraînement par le modèle `GradientBoostingRegressor` est de seulement 20.7 contre 1680 pour la régression linéaire. <br>\n",
    "> Le modèle `GradientBoostingRegressor` est très puissant et est capable d'apprendre les données d'entraînement **\"par cœur\"** ce qui explique cette différence de performance.\n",
    "> \n",
    "> C'est pour cette raison que la performance du modèle doit être évaluée sur le jeu de données de **test**. En effet, l'erreur absolue moyenne du modèle `GradientBoostingRegressor` est de 1442, ce qui est **très loin** de la performance obtenue sur les données d'entraînement. \n",
    "> \n",
    "> Ceci est un exemple de **surapprentissage flagrant**. <br>\n",
    "> Même si la performance du `GradientBoostingRegressor` est supérieure à celle de la régression linéaire sur les données de test, il faut **toujours se méfier** d'une performance trop élevée. \n",
    "\n",
    "## 3. Pour aller plus loin : la Régression Linéaire Polynomiale\n",
    "\n",
    "> Dans de nombreux cas, la relation entre les variables $x$ et $y$ **n'est pas linéaire**. <br>\n",
    "> Ceci ne nous permet pas d'utiliser la régression linéaire pour prédire $y$. Nous pourrions alors proposer un **modèle quadratique** tel que :\n",
    "> $$y = \\beta_0 + \\beta_1 x +\\beta_2 x^2 $$\n",
    "\n",
    "* **(a)** Exécuter la cellule suivante pour afficher la figure interactive.\n",
    "\n",
    "\n",
    "* **(b)** Trouver les paramètres optimaux pour $\\beta_0$, $\\beta_1$ et $\\beta_2$ qui approximent le mieux le nuage de points.\n",
    "\n",
    "\n",
    "* **(c)** Fixer $\\beta_2$ à 0 et faire varier $\\beta_0$ et $\\beta_1$. Quel modèle reconnaissez-vous ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from widgets import polynomial_regression\n",
    "\n",
    "polynomial_regression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> La régression linéaire polynomiale revient à effectuer une regression linéaire classique à partir de **fonctions polynomiales de la variable explicative** de degré arbitraire. <br>\n",
    "> La régression polynomiale est beaucoup plus flexible que la regression linéaire classique car elle peut approcher tout type de fonction continue.\n",
    ">\n",
    "> Lorsque nous disposons de plusieurs variables explicatives, les variables polynomiales peuvent aussi être calculées par des produits entre les variables explicatives. <br>\n",
    "> Par exemple, si nous disposons de trois variables, alors le modèle de la régression polynomiale d'ordre 2 devient :\n",
    ">\n",
    "> $$ y \\approx \\beta_0 + \\beta_1 x_1^2 + \\beta_2 x_2^2 + \\beta_3 x_3^2 + \\beta_4 x_1 x_2 + \\beta_5 x_2 x_3 + \\beta_6 x_1 x_3 $$\n",
    ">\n",
    "> Si nous avions plus de variables explicatives ou voulions monter le degré de la régression polynomiale, le nombre de variables polynomiales **exploserait**, ce qui peut soulever un problème de **surapprentissage**.\n",
    "\n",
    "* **(d)** Exécuter la cellule suivante pour afficher la figure interactive.\n",
    ">Le nuage de points a été généré avec la même tendance que la figure précédente. La ligne rouge correspond à la fonction de régression polynomiale optimale obtenue sur ces données.\n",
    "\n",
    "\n",
    "* **(e)** En prenant en compte le nuage de points de la figure précédente, trouver le **degré** de la régression polynomiale qui capture le mieux la tendance du nuage de points.\n",
    "\n",
    "\n",
    "* **(f)** Fixer `d` à 20. Pensez-vous que cette fonction de regression donnerait de bonnes prédictions sur le nuage de point de la figure précédente ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from widgets import polynomial_regression2\n",
    "\n",
    "polynomial_regression2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> Pour entraîner un modèle de régression Polynomiale avec scikit-learn, nous devons d'abord calculer les **variables polynomiales** des données. <br>\n",
    "> Ceci se fait grâce à la classe **`PolynomialFeatures`** du sous-module `preprocessing` :\n",
    ">\n",
    "> ```python\n",
    "> from sklearn.preprocessing import PolynomialFeatures\n",
    ">\n",
    "> poly_feature_extractor = PolynomialFeatures(degree = 2)\n",
    "> ```\n",
    ">\n",
    "> Le paramètre **`degree`** définit le **degré** des features polynomiaux à calculer.\n",
    ">\n",
    "> L'objet `poly_feature_extractor` **n'est pas un modèle de prédiction**. <br>\n",
    "> Ce type d'objet est appelé **`Transformer`** et son utilisation se fait à l'aide de deux méthodes :\n",
    ">> * **`fit`** : **ne fait rien** dans ce cas. Cette méthode sert en général à calculer les paramètres nécessaires pour appliquer une transformation sur les données.\n",
    ">>\n",
    ">>\n",
    ">> * **`transform`** : Applique la transformation au jeu de données. Dans ce cas, la méthode renvoie les features polynomiaux du jeu de données.\n",
    ">\n",
    "> Ces deux méthodes peuvent être appelées simultanément à l'aide de la méthode **`fit_transform`**. <br>\n",
    "> Nous pouvons calculer les features polynomiaux sur `X_train` et `X_test` ainsi :\n",
    ">\n",
    "> ```python\n",
    "> X_train_poly = poly_feature_extractor.fit_transform(X_train)\n",
    ">\n",
    "> X_test_poly = poly_feature_extractor.transform(X_test)\n",
    "> ```\n",
    "\n",
    "* **(g)** Importer la classe `PolynomialFeatures` du sous-module `preprocessing`.\n",
    "\n",
    "\n",
    "* **(h)** Instancier un objet de la classe `PolynomialFeatures` avec l'argument **`degree = 3`** et le nommer `poly_feature_extractor`.\n",
    "\n",
    "\n",
    "* **(i)** Appliquer la transformation de `poly_feature_extractor` sur `X_train` et `X_test` et stocker les résultats dans `X_train_poly` et `X_test_poly`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "* **(j)** Entraîner un modèle de régression linéaire sur les données (`X_train_poly`, `y_train`). \n",
    "\n",
    "\n",
    "* **(k)** Évaluer ses performances sur les données d'entraînement et les données de test (`X_test_poly`, `y_test`). Sommes-nous dans un régime de surapprentissage ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## Conclusion et recap\n",
    "\n",
    "> Dans ce cours, vous avez été introduits à la résolution d'un problème de régression grâce au Machine Learning.\n",
    "> \n",
    "> Nous avons utilisé la bibliothèque `scikit-learn` pour instancier des modèles de régression comme `LinearRegression` ou `GradientBoostingRegressor` et appliquer des transformations sur les données comme l'extraction de variables polynomiales.\n",
    "> \n",
    "> Les **différentes étapes** que nous avons étudiées sont la base de toute résolution d'un problème de Machine Learning :\n",
    ">> * On prépare les données en séparant les variables **explicatives** de la variable **cible**.\n",
    ">> \n",
    ">> \n",
    ">> * On **sépare** le jeu de données en deux (un jeu d'**entraînement** et un jeu de **test**) à l'aide de la fonction `train_test_split` du sous-module `sklearn.model_selection`.\n",
    ">> \n",
    ">> \n",
    ">> * On **instancie** un modèle comme `LinearRegression` ou `GradientBoostingRegressor` grâce au constructeur de la classe.\n",
    ">> \n",
    ">> \n",
    ">> * On **entraîne** le modèle sur le jeu de données d'entraînement à l'aide de la méthode **`fit`**.\n",
    ">> \n",
    ">> \n",
    ">> * On effectue une **prédiction** sur les données de test grâce à la méthode **`predict`**.\n",
    ">> \n",
    ">> \n",
    ">> * On **évalue les performances** de notre modèle en calculant l'erreur entre ces prédictions et les véritables valeurs de la variable cible des données de **test**. \n",
    ">\n",
    "> L'évaluation de performances pour un modèle de régression se fait facilement grâce aux fonctions **`mean_squared_error`** ou **`mean_absolute_error`** du sous-module `metrics` de scikit-learn.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "owner": "DataScientest"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
